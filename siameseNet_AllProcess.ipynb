{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition using SiameseNetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. AntiSpoofing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2LRPnPcDIByl"
   },
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "from imutils import face_utils\n",
    "from scipy.spatial import distance as dist\n",
    "from imutils.video import VideoStream\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define two constants, one for the eye aspect ratio to indicate\n",
    "# blink and then a second constant for the number of consecutive\n",
    "# frames the eye must be below the threshold\n",
    "EYE_AR_THRESH = 0.23 #baseline\n",
    "EYE_AR_CONSEC_FRAMES = 3\n",
    "\n",
    "# eye landmarks\n",
    "eye_landmarks = \"shape_predictor_68_face_landmarks.dat\"\n",
    "# initialize the frame counters and the total number of blinks\n",
    "COUNTER = 0\n",
    "TOTAL = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 eye blink detector class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class eye_blink_detector():\n",
    "    def __init__(self):\n",
    "        # cargar modelo para detecction frontal de rostros\n",
    "        self.detector_faces = dlib.get_frontal_face_detector()\n",
    "        # cargar modelo para deteccion de puntos de ojos\n",
    "        self.predictor_eyes = dlib.shape_predictor(eye_landmarks)\n",
    "\n",
    "    def eye_blink(self,gray,rect,COUNTER,TOTAL):\n",
    "        (lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "        (rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "        # determine the facial landmarks for the face region, then\n",
    "        # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "        # array\n",
    "        shape = self.predictor_eyes(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        # extract the left and right eye coordinates, then use the\n",
    "        # coordinates to compute the eye aspect ratio for both eyes\n",
    "        leftEye = shape[lStart:lEnd]\n",
    "        rightEye = shape[rStart:rEnd]\n",
    "        leftEAR = self.eye_aspect_ratio(leftEye)\n",
    "        rightEAR = self.eye_aspect_ratio(rightEye)\n",
    "        # average the eye aspect ratio together for both eyes\n",
    "        ear = (leftEAR + rightEAR) / 2.0\n",
    "        # check to see if the eye aspect ratio is below the blink\n",
    "        # threshold, and if so, increment the blink frame counter\n",
    "        if ear < EYE_AR_THRESH:\n",
    "            COUNTER += 1\n",
    "        # otherwise, the eye aspect ratio is not below the blink\n",
    "        # threshold\n",
    "        else:\n",
    "            # if the eyes were closed for a sufficient number of\n",
    "            # then increment the total number of blinks\n",
    "            if COUNTER >= EYE_AR_CONSEC_FRAMES:\n",
    "                TOTAL += 1\n",
    "            # reset the eye frame counter\n",
    "            COUNTER = 0\n",
    "        return COUNTER,TOTAL\n",
    "\n",
    "    def eye_aspect_ratio(self,eye):\n",
    "        # compute the euclidean distances between the two sets of\n",
    "        # vertical eye landmarks (x, y)-coordinates\n",
    "        A = dist.euclidean(eye[1], eye[5])\n",
    "        B = dist.euclidean(eye[2], eye[4])\n",
    "        # compute the euclidean distance between the horizontal\n",
    "        # eye landmark (x, y)-coordinates\n",
    "        C = dist.euclidean(eye[0], eye[3])\n",
    "        # compute the eye aspect ratio\n",
    "        ear = (A + B) / (2.0 * C)\n",
    "        # return the eye aspect ratio\n",
    "        return ear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 eye blink detection function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_rectangles2array(rectangles,image):\n",
    "    res = np.array([])\n",
    "    for box in rectangles:\n",
    "        [x0,y0,x1,y1] = max(0, box.left()), max(0, box.top()), min(box.right(), image.shape[1]), min(box.bottom(), image.shape[0])\n",
    "        new_box = np.array([x0,y0,x1,y1])\n",
    "        if res.size == 0:\n",
    "            res = np.expand_dims(new_box,axis=0)\n",
    "        else:\n",
    "            res = np.vstack((res,new_box))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_areas(boxes):\n",
    "    areas = []\n",
    "    for box in boxes:\n",
    "        x0,y0,x1,y1 = box\n",
    "        area = (y1-y0)*(x1-x0)\n",
    "        areas.append(area)\n",
    "    return areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounding_box(img,box,match_name=[]):\n",
    "    for i in np.arange(len(box)):\n",
    "        x0,y0,x1,y1 = box[i]\n",
    "        img = cv2.rectangle(img,\n",
    "                    (x0,y0),\n",
    "                    (x1,y1),\n",
    "                    (0,255,0),3);\n",
    "        if not match_name:\n",
    "            continue\n",
    "        else:\n",
    "            cv2.putText(img, match_name[i], (x0, y0-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Get User's Verification images & Eye blinking Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instancio detector\n",
    "detector = eye_blink_detector()\n",
    "# iniciar variables para el detector de parapadeo\n",
    "COUNTER = 0\n",
    "TOTAL = 0\n",
    "video_path = \"data/videos/video.mp4\" #/content/video.mp4\n",
    "image_path = \"facedata/realTimeData/input/\"\n",
    "verification_path = \"facedata/realTimeData/verify/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_verification_images():\n",
    "    \n",
    "    verification_video_path = verification_path + \"video/video.mp4\"\n",
    "    if not(os.path.isdir(verification_path + \"video\")):\n",
    "        os.makedirs(verification_path + \"video\")\n",
    "        \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    # 저장될 영상은 mp4형식이다.\n",
    "    # 캠이 여러대인 경우 인자로 0, 1, 2, 3...을 넣어주면 된다.\n",
    "    # 캠으로부터 정보를 읽어들일 수 없는 경우 에러 메세지를 반환한다.\n",
    "    if cap.isOpened() == False:\n",
    "        print(\"Unable to read camera\")\n",
    "\n",
    "    # 캠으로부터 정보를 읽어들일 수 있으면,\n",
    "    else:\n",
    "        # 프레임의 정보 가져와 변수에 저장한다. \n",
    "        frame_width = int(cap.get(3))\n",
    "        frame_height = int(cap.get(4))\n",
    "        print(\"원을 그리듯이 고개를 돌려주세요\")\n",
    "\n",
    "        #캠으로 들어온 비디오를 따로 저장한다.\n",
    "        out = cv2.VideoWriter(verification_video_path,\n",
    "                            cv2.VideoWriter_fourcc('D', 'I', 'V', 'X'),\n",
    "                            10,\n",
    "                            (frame_width, frame_height) )\n",
    "\n",
    "\n",
    "        # 동영상은 사진을 여러장 이어서 보여주는 개념이다.\n",
    "        # 1초에 몇 장의 이미지가 들어가는지, fps(frame per second) 단위를 쓴다.\n",
    "        # 캠으로부터 이미지 한 장만을 받아올 게 아니므로, 반복문을 사용한다.\n",
    "        start_time = time.time()\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if ret == True:\n",
    "                out.write(frame)\n",
    "                cv2.imshow('frame', frame)\n",
    "                recording_time = time.time() - start_time\n",
    "                #esc를 입력하면, 이미지를 받아오길 멈추게 한다.\n",
    "                if cv2.waitKey(1) & 0xFF == 27: # esc누르면 종료\n",
    "                    break\n",
    "                elif recording_time > 10: #최대 10초 정도까지 촬영가능\n",
    "                    print(\"time over\")\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        # sql 커서와 커넥션을 다 사용하고 나면 연결을 닫아주듯이, 비디오캡쳐도 닫아준다.\n",
    "        cap.release()\n",
    "        # 파일도 더 이상 작성하지 않도록 한다.\n",
    "        out.release()\n",
    "\n",
    "        #화면에 띄운 창을 닫아준다.\n",
    "        cv2.destroyAllWindows()\n",
    "        return verification_video_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = input(\"Do you want User Registration? [y or n]: \")\n",
    "if (mode == 'Y' or mode == 'y') or not(os.path.isdir(verification_path)):\n",
    "    if not(os.path.isdir(verification_path)):\n",
    "        os.makedirs(verification_path)\n",
    "    verification_video_path = get_verification_images()\n",
    "    verification_image_path = verification_path\n",
    "    if not(os.path.isdir(verification_path)):\n",
    "        os.makedirs(verification_path)\n",
    "    vidcap = cv2.VideoCapture(verification_video_path)\n",
    "    fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "    all_frame = vidcap.get(cv2.CAP_PROP_FRAME_COUNT) #영상 총 프레임 수\n",
    "    multiplier = all_frame / 50 # 어떤 영상이든 50장 캡쳐하도록\n",
    "    count = 1\n",
    "    success = True\n",
    "    while success:\n",
    "        frameId = int(round(vidcap.get(1)))\n",
    "        success,image = vidcap.read()\n",
    "        if frameId % multiplier < 1 : # 몇 프레임 당 한번씩 캡쳐할지\n",
    "            cv2.imwrite(verification_image_path + \"image%d.jpg\" %count, image)\n",
    "            print(\"saved image image%d.jpg\" % count)\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- video -----------------------------\n",
    "# Eye blinking detection & Login\n",
    "\n",
    "vs = cv2.VideoCapture(0) #VideoStream(src=0).start()\n",
    "antiSpoofing = True\n",
    "\n",
    "frame_width = int(vs.get(3))\n",
    "frame_height = int(vs.get(4))\n",
    "\n",
    "#캠으로 들어온 비디오를 따로 저장한다.\n",
    "out = cv2.VideoWriter(video_path,\n",
    "                    cv2.VideoWriter_fourcc('D', 'I', 'V', 'X'),\n",
    "                    20,\n",
    "                    (frame_width, frame_height) )\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"눈을 깜박여주세요\\n\")\n",
    "while True:\n",
    "    star_time = time.time()\n",
    "    ret, im = vs.read()\n",
    "    if ret == True:\n",
    "        out.write(im)\n",
    "        cv2.imshow('frame', im)\n",
    "        im = cv2.flip(im, 1)\n",
    "        im = imutils.resize(im, width=720)\n",
    "        gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "        # detectar_rostro    \n",
    "        rectangles = detector.detector_faces(gray, 0)\n",
    "        boxes_face = convert_rectangles2array(rectangles,im)\n",
    "        if len(boxes_face)!=0:\n",
    "            # seleccionar el rostro con mas area\n",
    "            areas = get_areas(boxes_face)\n",
    "            index = np.argmax(areas)\n",
    "            rectangles = rectangles[index]\n",
    "            boxes_face = np.expand_dims(boxes_face[index],axis=0)\n",
    "            # blinks_detector\n",
    "            COUNTER,TOTAL = detector.eye_blink(gray,rectangles,COUNTER,TOTAL)\n",
    "            # agregar bounding box\n",
    "            img_post = bounding_box(im,boxes_face,['blinks: {}'.format(TOTAL)])\n",
    "            if TOTAL > 1 :\n",
    "                break\n",
    "        else:\n",
    "            img_post = im \n",
    "        # visualizacion \n",
    "        end_time = time.time() - star_time    \n",
    "        FPS = 1/end_time\n",
    "        cv2.putText(img_post,f\"FPS: {round(FPS,3)}\",(10,50),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)\n",
    "        cv2.imshow('blink_detection',img_post)\n",
    "        recording_time = time.time() - start_time\n",
    "        if TOTAL > 1 : #한번 이상 눈깜박거림\n",
    "            break\n",
    "        elif recording_time > 7: #약 7초 내에 blink감지 안되면\n",
    "            antiSpoofing = False\n",
    "            print(\"time over\")\n",
    "            break\n",
    "\n",
    "# sql 커서와 커넥션을 다 사용하고 나면 연결을 닫아주듯이, 비디오캡쳐도 닫아준다.\n",
    "vs.release()\n",
    "# 파일도 더 이상 작성하지 않도록 한다.\n",
    "out.release()\n",
    "\n",
    "#화면에 띄운 창을 닫아준다.\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if antiSpoofing:\n",
    "    print(\"PASS\")\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "    fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "    multiplier = fps*20\n",
    "    count = 1\n",
    "    success = True\n",
    "    while success:\n",
    "        frameId = int(round(vidcap.get(1)))\n",
    "        success,image = vidcap.read()\n",
    "        if frameId % multiplier < 1 :\n",
    "            cv2.imwrite(image_path + \"image%d.jpg\" %count, image)\n",
    "            print(\"saved image image%d.jpg\" % count)\n",
    "            count += 1\n",
    "else:\n",
    "    print(\"Spoofing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.path.isfile(image_path + \"1.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Face Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "14aeb-3A9TYO"
   },
   "source": [
    "### Pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oBPiL4Aoqjwk"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install pillow\n",
    "!pip install tqdm\n",
    "!pip install keras\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pEzDkyQOs-AB"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# import os\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O10BFXSipobN"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class DataLoader(object):\n",
    "    \"\"\"\n",
    "    Class for loading data from image files\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, width, height, cells, data_path, output_path):\n",
    "        \"\"\"\n",
    "        Proper width and height for each image.\n",
    "        \"\"\"\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.cells = cells\n",
    "        self.data_path = data_path\n",
    "        self.output_path = output_path\n",
    "\n",
    "    def _open_image(self, path):\n",
    "        \"\"\"\n",
    "        Using the Image library we open the image in the given path. The path must lead to a .jpg file.\n",
    "        We then resize it to 105x105 like in the paper (the dataset contains 250x250 images.)\n",
    "\n",
    "        Returns the image as a numpy array.\n",
    "        \"\"\"\n",
    "        image = Image.open(path)\n",
    "        image = image.resize((self.width, self.height))\n",
    "        data = np.asarray(image)\n",
    "        data = np.array(data, dtype='float64')\n",
    "        return data\n",
    "\n",
    "    def convert_image_to_array(self, person, image_num, data_path, predict=False):\n",
    "        \"\"\"\n",
    "        Given a person, image number and datapath, returns a numpy array which represents the image.\n",
    "        predict - whether this function is called during training or testing. If called when training, we must reshape\n",
    "        the images since the given dataset is not in the correct dimensions.\n",
    "        \"\"\"\n",
    "        max_zeros = 4\n",
    "        image_num = '0' * max_zeros + image_num\n",
    "        image_num = image_num[-max_zeros:]\n",
    "        #image_path = os.path.join(data_path, 'lfw2', person, f'{person}_{image_num}.jpg')\n",
    "        image_path = os.path.join(data_path, 'kfaceData_detect', person, f'{person}_{image_num}.jpg')\n",
    "        image_data = self._open_image(image_path)\n",
    "        #print(f\"Image data shape: {image_data.shape}\") ## 밑밑줄에서 오류시 Image_data의 현재 array확인을 위해 추가함\n",
    "        if not predict:\n",
    "            image_data = image_data.reshape(self.width, self.height, self.cells)\n",
    "        return image_data\n",
    "    \n",
    "    def convert_image_to_array_for_predictInput(self, person, image_num, data_path, predict=False):\n",
    "        \"\"\"\n",
    "        Given a person, image number and datapath, returns a numpy array which represents the image.\n",
    "        predict - whether this function is called during training or testing. If called when training, we must reshape\n",
    "        the images since the given dataset is not in the correct dimensions.\n",
    "        \"\"\"\n",
    "        max_zeros = 4\n",
    "        image_num = '0' * max_zeros + image_num\n",
    "        image_num = image_num[-max_zeros:]\n",
    "        #image_path = os.path.join(data_path, 'lfw2', person, f'{person}_{image_num}.jpg')\n",
    "        image_path = os.path.join(data_path, person, f'{person}_{image_num}.jpg')\n",
    "        image_data = self._open_image(image_path)\n",
    "        #print(f\"Image data shape: {image_data.shape}\") ## 밑밑줄에서 오류시 Image_data의 현재 array확인을 위해 추가함\n",
    "        if not predict:\n",
    "            image_data = image_data.reshape(self.width, self.height, self.cells)\n",
    "        return image_data\n",
    "\n",
    "    def load(self, set_name):\n",
    "        \"\"\"\n",
    "        Writes into the given output_path the images from the data_path.\n",
    "        dataset_type = train or test\n",
    "        \"\"\"\n",
    "        file_path = os.path.join(self.data_path, 'splits', f'{set_name}.txt')\n",
    "        print(file_path)\n",
    "        print('Loading dataset...')\n",
    "        x_first = []\n",
    "        x_second = []\n",
    "        y = []\n",
    "        names = []\n",
    "        with open(file_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        for line in tqdm.tqdm(lines):\n",
    "            line = line.split()\n",
    "            if len(line) == 4:  # Class 0 - non-identical\n",
    "                names.append(line)\n",
    "                first_person_name, first_image_num, second_person_name, second_image_num = line[0], line[1], line[2], \\\n",
    "                                                                                           line[3]\n",
    "                first_image = self.convert_image_to_array(person=first_person_name,\n",
    "                                                          image_num=first_image_num,\n",
    "                                                          data_path=self.data_path)\n",
    "                second_image = self.convert_image_to_array(person=second_person_name,\n",
    "                                                           image_num=second_image_num,\n",
    "                                                           data_path=self.data_path)\n",
    "                x_first.append(first_image)\n",
    "                x_second.append(second_image)\n",
    "                y.append(0)\n",
    "            elif len(line) == 3:  # Class 1 - identical\n",
    "                names.append(line)\n",
    "                person_name, first_image_num, second_image_num = line[0], line[1], line[2]\n",
    "                first_image = self.convert_image_to_array(person=person_name,\n",
    "                                                          image_num=first_image_num,\n",
    "                                                          data_path=self.data_path)\n",
    "                second_image = self.convert_image_to_array(person=person_name,\n",
    "                                                           image_num=second_image_num,\n",
    "                                                           data_path=self.data_path)\n",
    "                x_first.append(first_image)\n",
    "                x_second.append(second_image)\n",
    "                y.append(1)\n",
    "                \n",
    "            elif len(line) == 2:  # verification\n",
    "                names.append(line)\n",
    "                first_image_num, second_image_num = line[0], line[1]\n",
    "                first_image = self.convert_image_to_array_for_predictInput(person='input',\n",
    "                                                          image_num=first_image_num,\n",
    "                                                          data_path=self.data_path)\n",
    "                second_image = self.convert_image_to_array(person='verify',\n",
    "                                                           image_num=second_image_num,\n",
    "                                                           data_path=self.data_path)\n",
    "                x_first.append(first_image)\n",
    "                x_second.append(second_image)\n",
    "                y.append(2)\n",
    "                \n",
    "            elif len(line) == 1:\n",
    "                print(f'line with a single value: {line}')\n",
    "        print('Done loading dataset')\n",
    "        with open(self.output_path, 'wb') as f:\n",
    "            pickle.dump([[x_first, x_second], y, names], f)\n",
    "\n",
    "\n",
    "print(\"Loaded data loader\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 SiameseNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u5dO2Y-Bpo_x"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Input, Sequential, Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Lambda, BatchNormalization, Activation, \\\n",
    "    Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "class SiameseNetwork(object):\n",
    "    def __init__(self, seed, width, height, cells, loss, metrics, optimizer, dropout_rate):\n",
    "        \"\"\"\n",
    "        Seed - The seed used to initialize the weights\n",
    "        width, height, cells - used for defining the tensors used for the input images\n",
    "        loss, metrics, optimizer, dropout_rate - settings used for compiling the siamese model (e.g., 'Accuracy' and 'ADAM)\n",
    "        \"\"\"\n",
    "        \n",
    "        K.clear_session()\n",
    "        self.load_file = None\n",
    "        self.seed = seed\n",
    "        self.initialize_seed()\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        # Define the matrices for the input images\n",
    "        input_shape = (width, height, cells)\n",
    "        left_input = Input(input_shape)\n",
    "        right_input = Input(input_shape)\n",
    "\n",
    "        # Get the CNN architecture as presented in the paper (read the readme for more information)\n",
    "        model = self._get_architecture(input_shape)\n",
    "        encoded_l = model(left_input)\n",
    "        encoded_r = model(right_input)\n",
    "\n",
    "        # Add a layer to combine the two CNNs\n",
    "        L1_layer = Lambda(lambda tensors: K.abs(tensors[0] - tensors[1]))\n",
    "        L1_siamese_dist = L1_layer([encoded_l, encoded_r])\n",
    "        L1_siamese_dist = Dropout(dropout_rate)(L1_siamese_dist)\n",
    "\n",
    "        # An output layer with Sigmoid activation function\n",
    "        prediction = Dense(1, activation='sigmoid', bias_initializer=self.initialize_bias)(L1_siamese_dist)\n",
    "        \n",
    "        self.threshold = 0.9  # Set threshold for similarity percentage\n",
    "\n",
    "        siamese_net = Model(inputs=[left_input, right_input], outputs=prediction)\n",
    "        self.siamese_net = siamese_net\n",
    "        self.siamese_net.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "    def initialize_seed(self):\n",
    "        \"\"\"\n",
    "        Initialize seed all for environment\n",
    "        \"\"\"\n",
    "        os.environ['PYTHONHASHSEED'] = str(self.seed)\n",
    "        random.seed(self.seed)\n",
    "        np.random.seed(self.seed)\n",
    "        tf.random.set_seed(self.seed)\n",
    "\n",
    "    def initialize_weights(self, shape, dtype=None):\n",
    "        \"\"\"\n",
    "        Called when initializing the weights of the siamese model, uses the random_normal function of keras to return a\n",
    "        tensor with a normal distribution of weights.\n",
    "        \"\"\"\n",
    "        return K.random_normal(shape, mean=0.0, stddev=0.01, dtype=dtype, seed=self.seed)\n",
    "\n",
    "    def initialize_bias(self, shape, dtype=None):\n",
    "        \"\"\"\n",
    "        Called when initializing the biases of the siamese model, uses the random_normal function of keras to return a\n",
    "        tensor with a normal distribution of weights.\n",
    "        \"\"\"\n",
    "        return K.random_normal(shape, mean=0.5, stddev=0.01, dtype=dtype, seed=self.seed)\n",
    "\n",
    "    def _get_architecture(self, input_shape):\n",
    "        \"\"\"\n",
    "        Returns a Convolutional Neural Network based on the input shape given of the images. This is the CNN network\n",
    "        that is used inside the siamese model. Uses parameters from the siamese one shot paper.\n",
    "        \"\"\"\n",
    "        model = Sequential()\n",
    "        model.add(\n",
    "            Conv2D(filters=64,\n",
    "                   kernel_size=(10, 10),\n",
    "                   input_shape=input_shape,\n",
    "                   kernel_initializer=self.initialize_weights,\n",
    "                   kernel_regularizer=l2(2e-4),\n",
    "                   name='Conv1'\n",
    "                   ))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D())\n",
    "\n",
    "        model.add(\n",
    "            Conv2D(filters=128,\n",
    "                   kernel_size=(7, 7),\n",
    "                   kernel_initializer=self.initialize_weights,\n",
    "                   bias_initializer=self.initialize_bias,\n",
    "                   kernel_regularizer=l2(2e-4),\n",
    "                   name='Conv2'\n",
    "                   ))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D())\n",
    "\n",
    "        model.add(\n",
    "            Conv2D(filters=128,\n",
    "                   kernel_size=(4, 4),\n",
    "                   kernel_initializer=self.initialize_weights,\n",
    "                   bias_initializer=self.initialize_bias,\n",
    "                   kernel_regularizer=l2(2e-4),\n",
    "                   name='Conv3'\n",
    "                   ))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D())\n",
    "\n",
    "        model.add(\n",
    "            Conv2D(filters=256,\n",
    "                   kernel_size=(4, 4),\n",
    "                   kernel_initializer=self.initialize_weights,\n",
    "                   bias_initializer=self.initialize_bias,\n",
    "                   kernel_regularizer=l2(2e-4),\n",
    "                   name='Conv4'\n",
    "                   ))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(\n",
    "            Dense(4096,\n",
    "                  activation='sigmoid',\n",
    "                  kernel_initializer=self.initialize_weights,\n",
    "                  kernel_regularizer=l2(2e-3),\n",
    "                  bias_initializer=self.initialize_bias))\n",
    "        return model\n",
    "\n",
    "    def _load_weights(self, weights_file):\n",
    "        \"\"\"\n",
    "        A function that attempts to load pre-existing weight files for the siamese model. If it succeeds then returns\n",
    "        True and updates the weights, otherwise False.\n",
    "        :return True if the file is already exists\n",
    "        \"\"\"\n",
    "        self.siamese_net.summary()\n",
    "        self.load_file = weights_file\n",
    "        if os.path.exists(weights_file):  # if the file is already exists, load and return true\n",
    "            print('Loading pre-existed weights file')\n",
    "            self.siamese_net.load_weights(weights_file)\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def fit(self, weights_file, train_path, validation_size, batch_size, epochs, early_stopping, patience, min_delta):\n",
    "        \"\"\"\n",
    "        Function for fitting the model. If the weights already exist, just return the summary of the model. Otherwise,\n",
    "        perform a whole train/validation/test split and train the model with the given parameters.\n",
    "        \"\"\"\n",
    "        with open(train_path, 'rb') as f:\n",
    "            x_train, y_train, names = pickle.load(f)\n",
    "        \"\"\"\n",
    "        X_train[0]:  |----------x_train_0---------------------------|-------x_val_0--------|\n",
    "        X_train[1]:  |----------x_train_1---------------------------|-------x_val_1--------|\n",
    "        y_train:     |----------y_train_0 = y_train_1---------------|----y_val_0=y_val_1---|\n",
    "        \"\"\"\n",
    "        x_train_0, x_val_0, y_train_0, y_val_0 = train_test_split(x_train[0], y_train,\n",
    "                                                                  test_size=validation_size,\n",
    "                                                                  random_state=self.seed)\n",
    "        x_train_1, x_val_1, y_train_1, y_val_1 = train_test_split(x_train[1], y_train,\n",
    "                                                                  test_size=validation_size,\n",
    "                                                                  random_state=self.seed)\n",
    "        x_train_0 = np.array(x_train_0, dtype='float64')\n",
    "        x_val_0 = np.array(x_val_0, dtype='float64')\n",
    "        x_train_1 = np.array(x_train_1, dtype='float64')\n",
    "        x_val_1 = np.array(x_val_1, dtype='float64')\n",
    "        x_train = [x_train_0, x_train_1]\n",
    "        x_val = [x_val_0, x_val_1]\n",
    "        if y_train_0 != y_train_1 and y_val_0 != y_val_1:\n",
    "            raise Exception(\"y train lists or y validation list do not equal\")\n",
    "        y_train_both = np.array(y_train_0, dtype='float64')\n",
    "        y_val_both = np.array(y_val_0, dtype='float64')\n",
    "        if not self._load_weights(weights_file=weights_file):\n",
    "            print('No such pre-existed weights file')\n",
    "            print('Beginning to fit the model')\n",
    "            callback = []\n",
    "            if early_stopping:\n",
    "                \"\"\"\n",
    "                We used the EarlyStopping function monitoring on the validation loss with a minimum delta of 0.1\n",
    "                (Minimum change in the monitored quantity to qualify as an improvement, i.e.\n",
    "                an absolute change of less than min_delta, will count as no improvement.) and patience 5 \n",
    "                (Number of epochs with no improvement after which training will be stopped.).\n",
    "                The direction is automatically inferred from the name of the monitored quantity (‘auto’).\n",
    "                \"\"\"\n",
    "                es = EarlyStopping(monitor='val_loss', min_delta=min_delta, patience=patience, mode='auto', verbose=1)\n",
    "                callback.append(es)\n",
    "            self.siamese_net.fit(x_train, y_train_both, batch_size=batch_size, epochs=epochs,\n",
    "                                 validation_data=(x_val, y_val_both), callbacks=callback, verbose=1)\n",
    "            self.siamese_net.save_weights(self.load_file)\n",
    "        # evaluate on the testing set\n",
    "        loss, accuracy = self.siamese_net.evaluate(x_val, y_val_both, batch_size=batch_size)\n",
    "        print(f'Loss on Validation set: {loss}')\n",
    "        print(f'Accuracy on Validation set: {accuracy}')\n",
    "\n",
    "    def evaluate(self, test_file, batch_size, analyze=False):\n",
    "        \"\"\"\n",
    "        Function for evaluating the final model after training.\n",
    "        test_file - file path to the test file.\n",
    "        batch_size - the batch size used in training.\n",
    "\n",
    "        Returns the loss and accuracy results.\n",
    "        \"\"\"\n",
    "        with open(test_file, 'rb') as f:\n",
    "            x_test, y_test, names = pickle.load(f)\n",
    "        print(f'Available Metrics: {self.siamese_net.metrics_names}')\n",
    "        y_test = np.array(y_test, dtype='float64')\n",
    "        x_test[0] = np.array(x_test[0], dtype='float64')\n",
    "        x_test[1] = np.array(x_test[1], dtype='float64')\n",
    "        # evaluate on the test set\n",
    "        loss, accuracy = self.siamese_net.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "        if analyze:\n",
    "            self._analyze(x_test, y_test, names)\n",
    "        return loss, accuracy\n",
    "    \n",
    "    def predict(self, verify_file):\n",
    "        with open(verify_file, 'rb') as f:\n",
    "            x_verify, y, names = pickle.load(f)\n",
    "        print('\\nprediction')\n",
    "\n",
    "        x_verify[0] = np.array(x_verify[0], dtype='float64')\n",
    "        x_verify[1] = np.array(x_verify[1], dtype='float64')\n",
    "        y_pred = self.siamese_net.predict(x_verify)\n",
    "        return y_pred\n",
    "\n",
    "    def _analyze(self, x_test, y_test, names):\n",
    "        \"\"\"\n",
    "        Function used for evaluating our network in the methods proposed in the assignment.\n",
    "        We will find:\n",
    "        - The person who has 2 images that are the most dissimilar to each other\n",
    "        - The person with the two images that are the most similar to each other\n",
    "        - Two people with the most dissimilar images, and\n",
    "        - The two people with the most similar images.\n",
    "        \"\"\"\n",
    "        best_class_0_prob = 1  # correct classification for different people, y=0, prediction->0\n",
    "        best_class_0_name = None\n",
    "        worst_class_0_prob = 0  # misclassification for different people, y=0, prediction->1\n",
    "        worst_class_0_name = None\n",
    "        best_class_1_prob = 0  # correct classification for same people, y=1, prediction->1\n",
    "        best_class_1_name = None\n",
    "        worst_class_1_prob = 1  # misclassification for same people, y=1, prediction->0\n",
    "        worst_class_1_name = None\n",
    "        prob = self.siamese_net.predict(x_test)\n",
    "        for pair_index in range(len(names)):\n",
    "            name = names[pair_index]\n",
    "            y_pair = y_test[pair_index]\n",
    "            pair_prob = prob[pair_index][0]\n",
    "            if y_pair == 0:  # different people (actual)\n",
    "                if pair_prob < best_class_0_prob:  # correct classification for different people, y=0, prediction->0\n",
    "                    best_class_0_prob = pair_prob\n",
    "                    best_class_0_name = name\n",
    "                if pair_prob > worst_class_0_prob:  # misclassification for different people, y=0, prediction->1\n",
    "                    worst_class_0_prob = pair_prob\n",
    "                    worst_class_0_name = name\n",
    "            else:  # the same person (actual)\n",
    "                if pair_prob > best_class_1_prob:  # correct classification for same people, y=1, prediction->1\n",
    "                    best_class_1_prob = pair_prob\n",
    "                    best_class_1_name = name\n",
    "                if pair_prob < worst_class_1_prob:  # misclassification for same people, y=1, prediction->0\n",
    "                    worst_class_1_prob = pair_prob\n",
    "                    worst_class_1_name = name\n",
    "\n",
    "        print(f'correct classification for different people, y=0, prediction->0, name: {best_class_0_name} | prob: {best_class_0_prob}')\n",
    "        print(f'misclassification for different people, y=0, prediction->1, name: {worst_class_0_name} | prob: {worst_class_0_prob}')\n",
    "        print(f'correct classification for same people, y=1, prediction->1, name: {best_class_1_name} | prob: {best_class_1_prob}')\n",
    "        print(f'misclassification for same people, y=1, prediction->0, name: {worst_class_1_name} | prob: {worst_class_1_prob}')\n",
    "\n",
    "\n",
    "print(\"Loaded Siamese Network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Training, Testing, RealTime Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ohgCVhwgsQSU"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "path_separator = os.path.sep\n",
    "# Environment settings\n",
    "IS_COLAB = (os.name == 'posix')\n",
    "LOAD_DATA = not (os.name == 'posix')\n",
    "IS_EXPERIMENT = False ## False\n",
    "train_name = 'train'\n",
    "test_name = 'test'\n",
    "verify_name = 'verify' #RealTime Test용\n",
    "WIDTH = HEIGHT = 105\n",
    "CEELS = 3 #흑백사진(gray scaling 한것):1, koreanface처럼 컬러사진:3\n",
    "loss_type = \"binary_crossentropy\"\n",
    "validation_size = 0.2\n",
    "early_stopping = True\n",
    "VERIFY = True #RealTime Test 여부\n",
    "\n",
    "if IS_COLAB:\n",
    "    # the google drive folder we used\n",
    "    data_path = os.path.sep + os.path.join('content', 'drive', 'My\\ Drive', 'datasets', 'lfw2').replace('\\\\', '')\n",
    "else:\n",
    "    # locally\n",
    "    from data_loader import DataLoader\n",
    "    from siamese_network import SiameseNetwork\n",
    "\n",
    "    #data_path = os.path.join('lfwa', 'lfw2')\n",
    "    data_path = \"faceData\"\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "def run_combination(l, bs, ep, pat, md, seed, train_path, test_path):\n",
    "    \"\"\"\n",
    "    This function gets the parameters and run the experiment.\n",
    "    :return: loss - loss on the testing set, accuracy - accuracy on the testing set\n",
    "    \"\"\"\n",
    "    # file types\n",
    "    model_save_type = 'h5'\n",
    "    # files paths\n",
    "    initialize_seed(seed)\n",
    "    parameters_name = f'seed_{seed}_lr_{l}_bs_{bs}_ep_{ep}_val_{validation_size}_' \\\n",
    "                      f'es_{early_stopping}_pa_{pat}_md_{md}'\n",
    "    print(f'Running combination with {parameters_name}')\n",
    "    # A path for the weights\n",
    "    load_weights_path = os.path.join(data_path, 'weights', f'weights_{parameters_name}.{model_save_type}')\n",
    "\n",
    "    siamese = SiameseNetwork(seed=seed, width=WIDTH, height=HEIGHT, cells=CEELS, loss=loss_type, metrics=['accuracy'],\n",
    "                             optimizer=Adam(lr=l), dropout_rate=0.4)\n",
    "    siamese.fit(weights_file=load_weights_path, train_path=train_path, validation_size=validation_size,\n",
    "                batch_size=bs, epochs=ep, early_stopping=early_stopping, patience=pat,\n",
    "                min_delta=md)\n",
    "    loss, accuracy = siamese.evaluate(test_file=test_path, batch_size=bs, analyze=True)\n",
    "\n",
    "    print(f'Loss on Testing set: {loss}')\n",
    "    print(f'Accuracy on Testing set: {accuracy}')\n",
    "    \n",
    "    # predict_pairs(model) RealTime Test\n",
    "    if VERIFY:\n",
    "        data_set_save_type = 'pickle'\n",
    "        verify_file = os.path.join(data_path, f'{verify_name}.{data_set_save_type}')  # A path for the train file\n",
    "        verify_path = os.path.join('faceData','realTimeData')\n",
    "        if LOAD_DATA:  # If the verify data already exists\n",
    "            loader = DataLoader(width=WIDTH, height=HEIGHT, cells=CEELS, data_path=verify_path, output_path=verify_file)\n",
    "            loader.load(set_name=verify_name)\n",
    "        y_pred = siamese.predict(verify_file)\n",
    "        print(y_pred)\n",
    "            \n",
    "    return loss, accuracy\n",
    "\n",
    "\n",
    "def run():\n",
    "    \"\"\"\n",
    "    The main function that runs the training and experiments. Uses the global variables above.\n",
    "    \"\"\"\n",
    "    # file types\n",
    "    data_set_save_type = 'pickle'\n",
    "    train_path = os.path.join(data_path, f'{train_name}.{data_set_save_type}')  # A path for the train file\n",
    "    test_path = os.path.join(data_path, f'{test_name}.{data_set_save_type}')  # A path for the test file\n",
    "    if LOAD_DATA:  # If the training data already exists\n",
    "        loader = DataLoader(width=WIDTH, height=HEIGHT, cells=CEELS, data_path=data_path, output_path=train_path)\n",
    "        loader.load(set_name=train_name)\n",
    "        loader = DataLoader(width=WIDTH, height=HEIGHT, cells=CEELS, data_path=data_path, output_path=test_path)\n",
    "        loader.load(set_name=test_name)\n",
    "\n",
    "    result_path = os.path.join(data_path, f'results.csv')  # A path for the train file\n",
    "    results = {'lr': [], 'batch_size': [], 'epochs': [], 'patience': [], 'min_delta': [], 'seed': [], 'loss': [],\n",
    "               'accuracy': []}\n",
    "    for l in lr:\n",
    "        for bs in batch_size:\n",
    "            for ep in epochs:\n",
    "                for pat in patience:\n",
    "                    for md in min_delta:\n",
    "                        for seed in seeds:\n",
    "                            siamese, loss, accuracy = run_combination(l=l, bs=bs, ep=ep, pat=pat, md=md, seed=seed,\n",
    "                                                             train_path=train_path, test_path=test_path)\n",
    "                            results['lr'].append(l)\n",
    "                            results['batch_size'].append(bs)\n",
    "                            results['epochs'].append(ep)\n",
    "                            results['patience'].append(pat)\n",
    "                            results['min_delta'].append(md)\n",
    "                            results['seed'].append(seed)\n",
    "                            results['loss'].append(loss)\n",
    "                            results['accuracy'].append(accuracy)\n",
    "    df_results = pd.DataFrame.from_dict(results)\n",
    "    df_results.to_csv(result_path)\n",
    "\n",
    "\n",
    "def initialize_seed(seed):\n",
    "    \"\"\"\n",
    "    Initialize all relevant environments with the seed.\n",
    "    \"\"\"\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if IS_EXPERIMENT:\n",
    "        # Experiments settings\n",
    "        seeds = [0]\n",
    "        lr = [0.00005]\n",
    "        batch_size = [32]\n",
    "        epochs = [10]\n",
    "        patience = [5]\n",
    "        min_delta = [0.1]\n",
    "    else:\n",
    "        # Final settings\n",
    "        seeds = [0]\n",
    "        lr = [0.00005]\n",
    "        batch_size = [32]\n",
    "        epochs = [10]\n",
    "        patience = [5]\n",
    "        min_delta = [0.1]\n",
    "\n",
    "    print(os.name)\n",
    "    start_time = time.time()\n",
    "    print('Starting the experiments')\n",
    "    run()\n",
    "    print(f'Total Running Time: {time.time() - start_time}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "siamese.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
